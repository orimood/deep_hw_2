{
  "loss": "BCE",
  "gamma": 0.1,
  "epochs": 20,
  "dataset": "LFW Aligned",
  "optimizer": "Adam",
  "scheduler": "StepLR",
  "step_size": 10,
  "batch_size": 32,
  "architecture": "Siamese Network",
  "weight_decay": 0.0005,
  "learning_rate": 0.0001
}