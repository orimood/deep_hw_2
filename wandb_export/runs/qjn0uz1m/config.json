{
  "loss": "BCEWithLogitsLoss",
  "gamma": 0.1,
  "epochs": 20,
  "dataset": "LFW Aligned",
  "dropout": "0.5 (embedding) / 0.5, 0.4 (similarity head)",
  "optimizer": "Adam",
  "scheduler": "StepLR",
  "step_size": 10,
  "batch_size": 32,
  "architecture": "Improved Siamese Network",
  "improvements": "BatchNorm + Multi-Channel Similarity + BCEWithLogitsLoss + Higher Dropout",
  "weight_decay": 0.001,
  "embedding_dim": 512,
  "learning_rate": 0.0001,
  "similarity_channels": "L1 + L2 + Cosine + Dot"
}